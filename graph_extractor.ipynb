{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ed3c93-53fe-4b76-97c3-bbc0f7b4d0c1",
   "metadata": {},
   "source": [
    "# Graph extraction with Gemini and SurrealDB\n",
    "\n",
    "    This notebook demonstrates the process of extracting a knowledge graph from unstructured text and storing it in the SurrealDB database. The process involves several steps:\n",
    "\n",
    "### Data Loading: \n",
    "    Loads the raw text data from which the knowledge graph will be extracted.\n",
    "\n",
    "\n",
    "### Using an LLM (in this example Gemini):\n",
    "\n",
    "    Using a prompt template (prompts.py) modified from a Microsoft GraphRag example we ask Gemini to do the following\n",
    "\n",
    "#### Entity Recognition: \n",
    "    Identifies and extracts key entities (people, organizations, locations, etc.) from the text. \n",
    "\n",
    "#### Relationship Extraction:\n",
    "    Determines relationships between the extracted entities.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constructing the Knowledge Graph with Surreal: \n",
    "    Converts the extracted entities and relationships into a knowledge graph stored in SurrealDB. This involves:\n",
    "\n",
    "        Mapping entities to nodes and relationships to edges in the graph.\n",
    "\n",
    "        Using SurrQL statements (CREATE for nodes, RELATE for edges) to populate the knowledge graph in the database.\n",
    "\n",
    "\n",
    "### Connecting to SurrealDB:\n",
    "    Establishes a connection to the SurrealDB instance. This  involves:\n",
    "    \n",
    "        If SurrealDB isn't running execute the start command in a terminal\n",
    "\n",
    "        Specifying the connection parameters (e.g., ws://localhost:8000/rpc).\n",
    "\n",
    "        Authenticating with the database using credentials (e.g., username and password).\n",
    "\n",
    "        Selecting the appropriate namespace for the knowledge graph.\n",
    "\n",
    "\n",
    "\n",
    "### Generating and Storing Embeddings: \n",
    "    Improves semantic search capabilities within the knowledge graph by:\n",
    "\n",
    "        Using an embedding model (glove.6B.50d in this example hosted on a Flask app) to generate numerical representations of entities and relationships. \n",
    "\n",
    "        Storing these embeddings as properties of the nodes and edges in SurrealDB, allowing for similarity-based searches.\n",
    "\n",
    "\n",
    "### Visualizing the graph:\n",
    "    We use the networkx library to render the graph visually that has been stored in SurreaDB\n",
    "\n",
    "\n",
    "#### notes\n",
    "    This notebook utilizes libraries :\n",
    "        surrealdb to interact with SurrealDB\n",
    "        google.generativeai to interact with Gemini\n",
    "        networkx to visualize the graph\n",
    "\n",
    "    The notebook is loosely based on a larger repository microsoft/graphrag. The microsoft/graphrag repository provides a more comprehensive, modular graph-based RAG system. This notebook focuses specifically on the knowledge graph construction aspect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba5a0d2-4780-40fe-95f9-49dd8e6cffc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/tgrdff7s5zx8m60rvp4tl_qc0000gp/T/ipykernel_46673/1405053571.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "from IPython.display import JSON\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "import ipynb_path\n",
    "\n",
    "pkg_resources.require(\"surrealdb==0.3.1\")\n",
    "from surrealdb import Surreal;\n",
    "import pandas as pd\n",
    "\n",
    "#get this notebook's path for access to the other files needed\n",
    "dir_path = os.path.dirname(os.path.realpath(ipynb_path.get(__name__)))\n",
    "sys.path.append(dir_path) #add the current directory for adding py imports\n",
    "from prompts import CONTINUE_PROMPT, GRAPH_EXTRACTION_PROMPT, LOOP_PROMPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac70fe6-a41f-4837-a913-58f0f175d5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52c5c28-ff9d-4102-848e-e0b98eefc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this folder\n",
    "nb_folder = dir_path\n",
    "out_folder = nb_folder + \"/{0}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "input_file = nb_folder + \"/Operation Dulce v2 1 1.md\"\n",
    "surql_file = out_folder + \"/inserts.suql\"\n",
    "chat_file = out_folder + \"/chat.json\"\n",
    "\n",
    "\n",
    "\n",
    "# make sure to start deliminater with # to escape it in SQL\n",
    "COMPLETION_DELEMITER = \"#XXXXXXCOMPLETEXXXXXX\" \n",
    "MAX_RETRIES = 10\n",
    "\n",
    "# get the text from the source file to create a knowledge graph of \n",
    "with open(input_file, \"r\") as f:\n",
    "    input_text = f.read()\n",
    "\n",
    "entity_types = [\"PERSON\", \"PLACE\"]\n",
    "relation_type = \"RELATED_TO\"\n",
    "\n",
    "# entity types should be the objects that you will find in the document\n",
    "# each entity type listed will create tables of the same name\n",
    "# the relate table will be names relation_type\n",
    "sql_gen_prompt = GRAPH_EXTRACTION_PROMPT.format(\n",
    "    entity_types = \",\".join(entity_types),\n",
    "    record_delimiter = \";\\n\",\n",
    "    completion_delimiter = COMPLETION_DELEMITER,\n",
    "    input_text = input_text,\n",
    "    relation_type = relation_type\n",
    "        )\n",
    "\n",
    "continue_prompt_with_completion = CONTINUE_PROMPT.format(\n",
    "    completion_delimiter = COMPLETION_DELEMITER\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa2e9496-6817-4c4c-b8de-2ed5d28e9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this function will recursively call a prompt until\n",
    "# the prompt ends with the COMPLETION_DELIMINATER \n",
    "# or exceeds the max number of tries\n",
    "def generate_content_until_complete(the_model,the_messages,retry_count):\n",
    "    time.sleep(5) # to stop generating too many requests per min\n",
    "    response = the_model.generate_content(the_messages)\n",
    "    ai_response_text = response.text\n",
    "    \n",
    "    #confirm the response ends with the correct delemiter\n",
    "    if ai_response_text.strip().endswith(COMPLETION_DELEMITER):\n",
    "        return response\n",
    "    else:\n",
    "        retry_count = retry_count + 1\n",
    "        if retry_count > MAX_RETRIES:\n",
    "            raise Exception(\"Too many retries {0}\".format(retry_count))\n",
    "        else:\n",
    "            #try again!\n",
    "            return generate_content_until_complete(the_model,the_messages,retry_count)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3b3748-ffe4-4d62-8f1c-b1a47f297302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching the graph ...\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: sql_gen_prompt}]}\n\u001b[1;32m     15\u001b[0m         ]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfetching the graph ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_content_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m ai_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#add the response to the chat history\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mgenerate_content_until_complete\u001b[0;34m(the_model, the_messages, retry_count)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_content_until_complete\u001b[39m(the_model,the_messages,retry_count):\n\u001b[1;32m      5\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;66;03m# to stop generating too many requests per min\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mthe_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     ai_response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#confirm the response ends with the correct delemiter\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set your API key (I've stored mine in an env variable)\n",
    "genai.configure(api_key=os.getenv('GOOGLE_GENAI_API_KEY'))\n",
    "\n",
    "#flash is faster and good enough\n",
    "model = \"gemini-1.0-pro\"\n",
    "#model = \"gemini-1.5-flash\"\n",
    "\n",
    "model = genai.GenerativeModel(model)\n",
    "\n",
    "#messages is the array that stores the entire chat history\n",
    "#it will need to be amended with each exchange with the LLM\n",
    "#the LLM will receive this with the new prompts each time to maintain session/memory\n",
    "messages = [\n",
    "            {\"role\": \"user\", \"parts\": [{\"text\": sql_gen_prompt}]}\n",
    "        ]\n",
    "\n",
    "\n",
    "print(\"fetching the graph ...\")\n",
    "response = generate_content_until_complete(model,messages,1)\n",
    "ai_response = response.text\n",
    "\n",
    "#add the response to the chat history\n",
    "messages.append({\"role\": \"model\", \"parts\": [{\"text\": ai_response}]})\n",
    "\n",
    "#surql will store the DML statements to execute\n",
    "surql = []\n",
    "surql.append(ai_response)\n",
    "\n",
    "# execute this loop while LLM decries there are more relations to decipher\n",
    "# and the the iterations doesn't exceed our threshold \n",
    "more_relations = True\n",
    "i = 0\n",
    "\n",
    "\n",
    "#logging\n",
    "with open(chat_file, \"w\") as f:\n",
    "    json.dump(messages, f)\n",
    "with open(surql_file, \"w\") as f:\n",
    "    for line in surql:\n",
    "        f.write(line + \"\\n\") \n",
    "\n",
    "while more_relations and i<MAX_RETRIES:\n",
    "    i = i + 1\n",
    "    print(\"fetching more relations N={0}... \".format(i), end=\"\")\n",
    "\n",
    "    #ask the LLM if it missed anything\n",
    "    messages.append({\"role\": \"user\", \"parts\": [{\"text\": LOOP_PROMPT}]})\n",
    "\n",
    "    response = model.generate_content(messages)\n",
    "    ai_response = response.text.strip()\n",
    "    \n",
    "    messages.append({\"role\": \"model\", \"parts\": [{\"text\": ai_response}]})\n",
    "\n",
    "    \n",
    "    more_relations = (ai_response == \"YES\")\n",
    "    print(\" continue? {0}\".format(ai_response))\n",
    "     \n",
    "    # if the LLM responds with yes then we will ask it for more\n",
    "    if(more_relations):\n",
    "        \n",
    "        # ask the LLM to add more relations and objects that it said it missed\n",
    "        messages.append({\"role\": \"user\", \"parts\": [{\"text\": continue_prompt_with_completion}]})\n",
    "        \n",
    "        response = generate_content_until_complete(model,messages,1)\n",
    "         \n",
    "        ai_response = response.text\n",
    "        \n",
    "        messages.append({\"role\": \"model\", \"parts\": [{\"text\": ai_response}]})\n",
    "\n",
    "        \n",
    "        surql.append(ai_response)\n",
    "        \n",
    "\n",
    "    \n",
    "    with open(chat_file, \"w\") as f:\n",
    "        json.dump(messages, f)\n",
    "        \n",
    "    with open(surql_file, \"w\") as f:\n",
    "        for line in surql:\n",
    "            f.write(line + \"\\n\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfd19b-4ec2-4e82-81b1-faedfc1c504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#now we have our surQL code to execute so let's connect make sure our database is up and running\n",
    "\n",
    "ip = \"0.0.0.0:8080\"\n",
    "url = \"ws://{0}/rpc\".format(ip)\n",
    "\n",
    "u = \"root\"\n",
    "p = \"root\"\n",
    "n = \"graph_rag\"\n",
    "d = \"graph_rag\"\n",
    "db_folder = nb_folder + \"/db\"\n",
    "\n",
    "surrealdb_start = \"surreal start --allow-net --log none --user {u} --pass {p} --bind {ip} \\\"rocksdb://{db_folder}\\\"\".format(\n",
    "    u=u,\n",
    "    p=p,\n",
    "    ip=ip,\n",
    "    db_folder=db_folder)\n",
    "\n",
    "#run this command if your surreal instance isn't running yet \n",
    "#copy and paste from below into a terminal\n",
    "print(surrealdb_start)\n",
    "\n",
    "#ensure the embedding service is running as well\n",
    "\"\"\"\n",
    "cd embedding_api\n",
    "env FLASK_APP=embedding_api.py python -m flask --app embedding_api --debug run \n",
    "\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfb936-4a61-4f33-846b-4648408150c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#drop the data from any previous run and re-create the ns and db\n",
    "recreate_db_surql = \"\"\"\n",
    "DEFINE NAMESPACE OVERWRITE {0};\n",
    "DEFINE DATABASE OVERWRITE {1};\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#create the function that will do calculate embeddings\n",
    "#this is hosted on an api running locally BYOE or use a hosted one as you see fit\n",
    "embedding_function_surql = \"\"\"\n",
    "DEFINE FUNCTION IF NOT EXISTS fn::get_embeddings($text: string) {\n",
    "\tRETURN http::post('http://127.0.0.1:5000/', {\n",
    "      \"text\":  $text\n",
    "    });\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "#this DDL will create the entity tables\n",
    "recreate_table_surql = \"\"\"\n",
    "REMOVE TABLE IF EXISTS {0};\n",
    "DEFINE TABLE {0} SCHEMAFULL;\n",
    "DEFINE FIELD description ON TABLE {0} TYPE string;\n",
    "DEFINE FIELD embedding ON TABLE {0} TYPE option<array<float>> \n",
    "    VALUE fn::get_embeddings( description);\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#this DDL will create the relation table\n",
    "recreate_relate_table_surql = \"\"\"\n",
    "REMOVE TABLE IF EXISTS {relation_type};\n",
    "DEFINE TABLE {relation_type} SCHEMAFULL TYPE RELATION FROM {entity_type1} TO {entity_type1}|{entity_type2};\n",
    "DEFINE FIELD description ON TABLE {relation_type} TYPE string;\n",
    "DEFINE FIELD strength ON TABLE {relation_type} TYPE int;\n",
    "DEFINE FIELD embedding ON TABLE {relation_type} TYPE option<array<float>> \n",
    "    VALUE fn::get_embeddings(description);\n",
    "\"\"\"\n",
    "\n",
    "#this is a sample query after inserts\n",
    "sample_query = \"\"\"\n",
    "\n",
    "SELECT id,description, ->{relation_type}.{{out,strength,description}} FROM {entity_type} \n",
    "\n",
    "        \"\"\"\n",
    "#this will pull all the entities for displaying in a diagram later\n",
    "entity_query = \"SELECT * FROM {entity_type}\"\n",
    "#this will pull all the relations for displaying in a diagram later\n",
    "relation_query = \"SELECT * FROM {relation_type}\"\n",
    "\n",
    "\n",
    "\n",
    "async with Surreal(url) as db:\n",
    "    await db.signin({\"user\": u, \"pass\": p})    \n",
    "    outcome = await db.query(recreate_db_surql.format(n,d))\n",
    "    await db.use(n, d)\n",
    "    outcome = await db.query(embedding_function_surql)\n",
    "    outcome = await db.query(recreate_table_surql.format(entity_types[0]))\n",
    "    outcome = await db.query(recreate_table_surql.format(entity_types[1]))\n",
    "    \n",
    "    outcome = await db.query(recreate_relate_table_surql.format(relation_type = relation_type, entity_type1 = entity_types[0], entity_type2 = entity_types[1]))\n",
    "\n",
    "    for line in surql:\n",
    "        outcome = await db.query(line)\n",
    "    sample_query_outcome = await db.query(sample_query.format(relation_type = relation_type, entity_type = entity_types[0]))\n",
    "    entity_query_outcome1 = await db.query(entity_query.format(entity_type = entity_types[0]))\n",
    "    entity_query_outcome2 = await db.query(entity_query.format(entity_type = entity_types[1]))\n",
    "    relation_query_outcome = await db.query(relation_query.format(relation_type = relation_type))\n",
    "    \n",
    "df = pd.json_normalize(sample_query_outcome[0][\"result\"])  \n",
    "edf1 = pd.json_normalize(entity_query_outcome1[0][\"result\"])  \n",
    "edf2 = pd.json_normalize(entity_query_outcome2[0][\"result\"]) \n",
    "rdf = pd.json_normalize(relation_query_outcome[0][\"result\"])\n",
    "\n",
    "df.head\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9497837-870d-446a-a2ed-aec414013f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#this function parses out the nested list that contains the relations in this query\n",
    "def format_nested_array(x):\n",
    "    if isinstance(x, list):\n",
    "        \n",
    "        return \"<br>\".join(str(item[\"out\"]) + \"-\" + str(item[\"strength\"]) for item in x) \n",
    "    return x\n",
    "\n",
    "#reorder the columns \n",
    "df2 = df.iloc[:,[2,1,0]]\n",
    "\n",
    "#print the sample query\n",
    "df2.style.format({\"->RELATED_TO\": format_nested_array})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc16bc-cf7f-4a7e-b2f0-628c35382484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's visualize the graph\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create a graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "#add a node for each entity\n",
    "for index, row in edf1.iterrows():\n",
    "    G.add_node(row['id'], entity_type=entity_types[0])\n",
    "    \n",
    "for index, row2 in edf2.iterrows():\n",
    "    G.add_node(row2['id'],  entity_type=entity_types[1])\n",
    "    \n",
    "\n",
    "#add an edge for each relationship\n",
    "for index, row3 in rdf.iterrows():\n",
    "    G.add_edge(row3['in'],row3['out'],label=row3[\"strength\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #generate a color map for rendering the nodes\n",
    "# color_map = nx.get_node_attributes(G,\"entity_type\")\n",
    "# for key in color_map:\n",
    "#     if color_map[key] == entity_types[0]:\n",
    "#         color_map[key] = \"red\"\n",
    "#     else:\n",
    "#         color_map[key] = \"blue\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "color_map =[]\n",
    "for node in G.nodes.items(): \n",
    "    if node[1].__contains__(\"entity_type\") and node[1][\"entity_type\"] == entity_types[0]:\n",
    "        color_map.append( \"red\")\n",
    "    else:\n",
    "        color_map.append( \"blue\")\n",
    "\n",
    "#add an edge for each relationship\n",
    "for index, row in rdf.iterrows():\n",
    "    G.add_edge(row['in'],row['out'],label=row[\"strength\"])\n",
    "\n",
    "\n",
    "# Draw the graph\n",
    "#pos = nx.spring_layout(G)  # Use spring layout for node positioning\n",
    "#pos=nx.fruchterman_reingold_layout(G)\n",
    "pos=nx.circular_layout(G)\n",
    "#pos=nx.random_layout(G)\n",
    "#pos=nx.spectral_layout(G)\n",
    "# nx.draw(G, pos, with_labels=True, node_size=10, font_size=6, \n",
    "#        horizontalalignment='right')\n",
    "nx.draw(G, pos, with_labels=True, node_size=10, font_size=6, node_color=color_map,\n",
    "      horizontalalignment='right')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'label'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc1a56-40d8-4145-b53c-2dd904ee9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mm(graph,width,height):\n",
    "    graphbytes = graph.encode(\"utf8\")\n",
    "    base64_bytes = base64.urlsafe_b64encode(graphbytes)\n",
    "    base64_string = base64_bytes.decode(\"ascii\")\n",
    "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string, width=width, height=height))\n",
    "\n",
    "mm(\"\"\"graph TD\n",
    "    A(Marie Curie):::person -->|is a| B(Scientist):::award\n",
    "    A -->|won| C(Nobel Prize):::award\n",
    "\n",
    "    classDef person fill:#ff42a1,stroke:#0;\n",
    "    classDef award fill:#e100ff,stroke:#0;\"\"\",300,300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc009970-1d88-43d8-8c80-156357c4a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mermaid_js = \"graph LR\\n\"\n",
    "\n",
    "#add a node for each entity\n",
    "\n",
    "badidchars = ['`','⟨','⟩',':',\" \"]\n",
    "badchars = ['⟨','⟩',':',entity_types[0],entity_types[1]]\n",
    "\n",
    "for index, row in edf1.iterrows():\n",
    "    id1 = row['id']\n",
    "    nm1 = row['id']\n",
    "    for ch in badidchars:\n",
    "        id1 = id1.replace(ch,\"\")\n",
    "    for ch in badchars:\n",
    "        nm1 = nm1.replace(ch,\" \").strip()\n",
    "    mermaid_js += \"\\t{0}({1}):::{2}\\n\".format(id1,nm1,entity_types[0])\n",
    "    \n",
    "for index, row in edf2.iterrows():\n",
    "    id1 = row['id']\n",
    "    nm1 = row['id']\n",
    "    for ch in badidchars:\n",
    "        id1 = id1.replace(ch,\"\")\n",
    "    for ch in badchars:\n",
    "        nm1 = nm1.replace(ch,\" \").strip()\n",
    "    mermaid_js += \"\\t{0}({1}):::{2}\\n\".format(id1,nm1,entity_types[1])\n",
    "\n",
    "\n",
    "#add an edge for each relationship\n",
    "for index, row in rdf.iterrows():\n",
    "    id1 = row['in']\n",
    "    id2 = row['out']\n",
    "    \n",
    "    for ch in badidchars:\n",
    "        id1 = id1.replace(ch,\"\")\n",
    "        id2 = id2.replace(ch,\"\")\n",
    "    \n",
    "        \n",
    "    mermaid_js += \"\\t{0}-->|{1}| {2}\\n\".format(id1,row[\"strength\"],id2)\n",
    "\n",
    "mermaid_js += \"\"\"\n",
    "    classDef {0} fill:#ff42a1,stroke:#0;\n",
    "    classDef {1} fill:#e100ff,stroke:#0;\n",
    "    \"\"\".format(entity_types[0],entity_types[1])\n",
    "\n",
    "print(mermaid_js)\n",
    "\n",
    "\n",
    "mm (mermaid_js,300,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35eab2-01a7-4f3d-945e-7b0d5bfce8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858bd7d-5921-4b7f-852b-bbf73f5c5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recreate_relate_table_surql.format(relation_type = relation_type, entity_type1 = entity_types[0], entity_type2 = entity_types[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
