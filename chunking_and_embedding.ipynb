{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ed3c93-53fe-4b76-97c3-bbc0f7b4d0c1",
   "metadata": {},
   "source": [
    "# Chunking a Document for Semantic Search in SurrealDB\n",
    "\n",
    "    This notebook demonstrates the process of extracting chunks from a document and uploading the chunks to a table with embeddings calculated at upload.\n",
    "\n",
    "### Chunking: \n",
    "    A simple function that reads the file and splices it into chunks of a specified size. The default is 250 words which will translate to reasonable number of tokens.\n",
    "\n",
    "\n",
    "\n",
    "### Connecting to SurrealDB:\n",
    "    Establishes a connection to the SurrealDB instance. This  involves:\n",
    "    \n",
    "        If SurrealDB isn't running execute the start command in a terminal\n",
    "\n",
    "        Specifying the connection parameters (e.g., ws://localhost:8000/rpc).\n",
    "\n",
    "        Authenticating with the database using credentials (e.g., username and password).\n",
    "\n",
    "        Selecting the appropriate namespace for the knowledge graph.\n",
    "\n",
    "\n",
    "### Generating and Storing Embeddings: \n",
    "    Enables semantic search capabilities within the table by:\n",
    "\n",
    "        Using an embedding model (glove.6B.50d in this example) to generate numerical representations of entities and relationships. \n",
    "\n",
    "        Storing these embeddings as properties of the nodes and edges in SurrealDB, allowing for similarity-based searches.\n",
    "\n",
    "        Make sure to upload an embedding model to the database prior to inserting the graph to the database.\n",
    "\n",
    "        This repo is a prerequisite for uploading the embedding model:\n",
    "\n",
    "        https://github.com/apireno/surrealDB_embedding_model\n",
    "\n",
    "\n",
    "\n",
    "#### notes\n",
    "    This notebook utilizes libraries :\n",
    "        surrealdb to interact with SurrealDB\n",
    "\n",
    "    Prerquisite is to install the embedding model as in this python script:\n",
    "            https://github.com/apireno/surrealDB_embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba5a0d2-4780-40fe-95f9-49dd8e6cffc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/tgrdff7s5zx8m60rvp4tl_qc0000gp/T/ipykernel_91537/714487909.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import sys\n",
    "import os\n",
    "import os\n",
    "import time\n",
    "import ipynb_path\n",
    "\n",
    "from surrealdb import AsyncSurreal\n",
    "import pandas as pd\n",
    "\n",
    "#get this notebook's path for access to the other files needed\n",
    "dir_path = os.path.dirname(os.path.realpath(ipynb_path.get(__name__)))\n",
    "sys.path.append(dir_path) #add the current directory for adding py imports\n",
    "from prompts import CONTINUE_PROMPT, GRAPH_EXTRACTION_PROMPT, LOOP_PROMPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52c5c28-ff9d-4102-848e-e0b98eefc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this folder\n",
    "nb_folder = dir_path\n",
    "out_folder = nb_folder + \"/chunking_{0}\".format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "#the file to read the text from\n",
    "input_file = nb_folder + \"/Operation Dulce v2 1 1.txt\"\n",
    "\n",
    "#SurQL to exectue\n",
    "surql_file = out_folder + \"/inserts.suql\"\n",
    "\n",
    "#debugging file for logging \n",
    "debug = True\n",
    "debug_file = out_folder + \"/debug.txt\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa2e9496-6817-4c4c-b8de-2ed5d28e9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_file(input_file,chunk_size = 250):\n",
    "    \"\"\"\n",
    "    Chunks an input file into optimized sizes for LLM processing.\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to the input file.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings, where each string is a chunk of the file.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(input_file, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # This is a heuristic for chunk size, and may need adjustment\n",
    "    # depending on the specific LLM and its context window.\n",
    "    # It aims to create chunks that are large enough to provide context,\n",
    "    # but small enough to avoid exceeding the LLM's limits.\n",
    "    words = text.split()\n",
    "    # chunk_size = 250  # Approximately 1000-1500 characters\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunks.append(' '.join(words[i:i + chunk_size]))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca8f95a-2224-48dc-b517-9acc54c6c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many chunks? 77\n",
      "\n",
      "\n",
      "Lets see the first chunk:\n",
      "\n",
      "# Operation: Dulce ## Chapter 1 The thrumming of monitors cast a stark contrast to the rigid silence enveloping the group. Agent Alex Mercer, unfailingly determined on paper, seemed dwarfed by the enormity of the sterile briefing room where Paranormal Military Squad's elite convened. With dulled eyes, he scanned the projectors outlining their impending odyssey into Operation: Dulce. “I assume, Agent Mercer, you’re not having second thoughts?” It was Taylor Cruz’s voice, laced with an edge that demanded attention. Alex flickered a strained smile, still thumbing his folder's corner. \"Of course not, Agent Cruz. Just trying to soak in all the details.\" The compliance in his tone was unsettling, even to himself. Jordan Hayes, perched on the opposite side of the table, narrowed their eyes but offered a supportive nod. \"Details are imperative. We’ll need your clear-headedness down there, Mercer.\" A comfortable silence, the kind that threaded between veterans of shared secrets, lingered briefly before Sam Rivera, never one to submit to quiet, added, \"I’ve combed through the last transmission logs. If anyone can make sense of the anomalies, it’s going to be the two of you.\" Taylor snorted dismissively. “Focus, people. We have protocols for a reason. Speculation is counter-productive.” The words 'counter-productive' seemed to hang in the air, a tacit reprimand directed at Alex. Feeling the weight of his compliance conflicting with his natural inclination to leave no stone unturned, Alex straightened in his seat. \"I agree, Agent Cruz. Protocol is paramount,\" he said, meeting Taylor's steely gaze.\n"
     ]
    }
   ],
   "source": [
    "#let's chunk this file!\n",
    "\n",
    "chunks = chunk_file(input_file)\n",
    "\n",
    "print(f\"How many chunks? {len(chunks)}\")\n",
    "print(f\"\"\"\n",
    "\n",
    "Lets see the first chunk:\n",
    "\n",
    "{chunks[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bfd19b-4ec2-4e82-81b1-faedfc1c504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surreal start --allow-net --log none --user root --pass root --bind 0.0.0.0:8000 \"rocksdb:///Users/sandro/git_repos/graph_rag/db\"\n",
      "\n",
      "ensure you installed the embedding model!\n",
      "      \n",
      "      https://github.com/apireno/surrealDB_embedding_model\n",
      "\n",
      "the model will power the function fn::sentence_to_vector($text)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#now we have our surQL code to execute so let's connect make sure our database is up and running\n",
    "\n",
    "ip = \"0.0.0.0:8000\"\n",
    "url = \"ws://{0}\".format(ip)\n",
    "\n",
    "u = \"root\"\n",
    "p = \"root\"\n",
    "n = \"graph_rag\"\n",
    "d = \"graph_rag\"\n",
    "db_folder = nb_folder + \"/db\"\n",
    "\n",
    "surrealdb_start = \"surreal start --allow-net --log none --user {u} --pass {p} --bind {ip} \\\"rocksdb://{db_folder}\\\"\".format(\n",
    "    u=u,\n",
    "    p=p,\n",
    "    ip=ip,\n",
    "    db_folder=db_folder)\n",
    "\n",
    "#run this command if your surreal instance isn't running yet \n",
    "#copy and paste from below into a terminal\n",
    "print(surrealdb_start)\n",
    "\n",
    "#and ensure you installed the embedding model!\n",
    "#the model will power the function fn::sentence_to_vector($text)\n",
    "print(\"\"\"\n",
    "ensure you installed the embedding model!\n",
    "      \n",
    "      https://github.com/apireno/surrealDB_embedding_model\n",
    "\n",
    "the model will power the function fn::sentence_to_vector($text)\n",
    "\"\"\"   )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04cfb936-4a61-4f33-846b-4648408150c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    chunk\n",
      "count                                                  30\n",
      "unique                                                 30\n",
      "top     odyssey not of the body, but of the intellect ...\n",
      "freq                                                    1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                 chunk\n",
       "0   odyssey not of the body, but of the intellect ...\n",
       "1   team now faced the duality of their roles, pro...\n",
       "2   the team. Taylor observed them, a cold calcula...\n",
       "3   is no longer just about being heard—it's about...\n",
       "4   the screen. \"Responding? Like it’s alive?\" Tay...\n",
       "5   now thrummed with a different kind of energy, ...\n",
       "6   conspiracies and furtive movements. But in the...\n",
       "7   through the buzz of activity. \"Control may be ...\n",
       "8   Taylor Cruz interjected, looking up from a dat...\n",
       "9   each other, evolving together through this.. d...\n",
       "10  their harmony in the cosmic conversation. ## C...\n",
       "11  their back, regarded the unfolding scene, thei...\n",
       "12  anything.\" Alex's eyes brightened with a subtl...\n",
       "13  resonates—it's designed to be felt.\" The room ...\n",
       "14  of monitors cast an otherworldly ambiance upon...\n",
       "15  their undertaking. The agents were standing no...\n",
       "16  adversary a code from beyond the stars that he...\n",
       "17  hard tutelage of rank and order. But here, in ...\n",
       "18  fabric of their operations. \"Let's be the cart...\n",
       "19  possibilities beyond their rational understand...\n",
       "20  what Paranormal Military Squad does best—inves...\n",
       "21  a signal—a testament to the uncanny reality th...\n",
       "22  of Dulce base or confront whatever existential...\n",
       "23  of electronic machinery, the thrumming pulse o...\n",
       "24  nuances here are extraordinary,\" they acknowle...\n",
       "25  composed demeanor. \"And remember, this isn't j...\n",
       "26  Dulce team was a confluence of ambition and ac...\n",
       "27  an extension of unknown consciousness reaching...\n",
       "28  the sleek surface of an encrypted radio transm...\n",
       "29  our reply must be both innovative and discerni...>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#make sure the ns and db exist the ns and db\n",
    "recreate_db_surql = \"\"\"\n",
    "DEFINE NAMESPACE IF NOT EXISTS {0};\n",
    "DEFINE DATABASE IF NOT EXISTS {1};\n",
    "\"\"\"\n",
    "#the table we will insert into\n",
    "TABLE_NAME = \"CHUNKS\"\n",
    "\n",
    "\n",
    "#this DDL will create the entity tables\n",
    "#and create an index for searching the description\n",
    "#based on consine similarity of the GloVe embeddings of 50 dimensions\n",
    "recreate_table_surql = f\"\"\"\n",
    "REMOVE TABLE IF EXISTS {TABLE_NAME};\n",
    "DEFINE TABLE {TABLE_NAME} SCHEMAFULL;\n",
    "DEFINE FIELD chunk ON TABLE {TABLE_NAME} TYPE string;\n",
    "DEFINE FIELD embedding ON TABLE {TABLE_NAME} TYPE option<array<float>> \n",
    "    DEFAULT fn::sentence_to_vector( chunk);\n",
    "\n",
    "REMOVE INDEX IF EXISTS idx_{TABLE_NAME}_chunk ON TABLE {TABLE_NAME};\n",
    "DEFINE INDEX idx_{TABLE_NAME}_description ON TABLE {TABLE_NAME} FIELDS embedding MTREE DIMENSION 50 DIST COSINE;\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "insert_chunk_surql = f\"\"\"\n",
    "    INSERT INTO {TABLE_NAME} {{\n",
    "        chunk:$chunk\n",
    "    }} RETURN NONE;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#this is a sample query after inserts\n",
    "sample_query = f\"\"\"\n",
    "LET $v = fn::sentence_to_vector($q);\n",
    "SELECT chunk FROM {TABLE_NAME} WHERE  embedding <|30,COSINE|> $v;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#connect to the database\n",
    "async with AsyncSurreal(url) as db:\n",
    "    await db.signin( {\"username\":u, \"password\":p}) \n",
    "    #create the namespace and database\n",
    "    outcome = await db.query_raw(recreate_db_surql.format(n,d))\n",
    "    await db.use(n, d)\n",
    "\n",
    "    #create the entity tables\n",
    "    outcome = await db.query_raw(recreate_table_surql)\n",
    "    \n",
    "    #execute the surql extracted from the LLM line by line\n",
    "    for chunk in chunks:\n",
    "        params = {\"chunk\": chunk}\n",
    "        outcome = await db.query_raw(insert_chunk_surql, params)\n",
    "\n",
    "    #lets test the search\n",
    "    params = {\"q\": \"What is the name of this story?\"}\n",
    "\n",
    "\n",
    "    #run some sample queries and pull data to visualize the graph    \n",
    "    sample_query_outcome = await db.query_raw(sample_query,params)\n",
    "\n",
    "df = pd.json_normalize(sample_query_outcome[\"result\"][1][\"result\"] )\n",
    "print(df.describe())\n",
    "df.head\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35eab2-01a7-4f3d-945e-7b0d5bfce8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858bd7d-5921-4b7f-852b-bbf73f5c5182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
